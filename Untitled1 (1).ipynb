{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70d2198e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Conv2D,Flatten,Dense,MaxPool2D,BatchNormalization,GlobalAveragePooling2D\n",
    "from tensorflow.keras.applications.resnet50 import preprocess_input,decode_predictions\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator,load_img\n",
    "from tensorflow.keras.applications.resnet50 import ResNet50\n",
    "from tensorflow.keras.preprocessing import image\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from matplotlib import pyplot as plt\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import cv2\n",
    "import os\n",
    "from glob import glob\n",
    "\n",
    "img_height,img_width=(300,300)\n",
    "batch_size=32\n",
    "\n",
    "traindata_dir=r\"projectdataset\\\\output dataset\\\\train\"\n",
    "testdata_dir=r\"projectdataset\\\\output dataset\\\\test\"\n",
    "validationdata_dir=r\"projectdataset\\\\output dataset\\\\val\"\n",
    "\n",
    "os.getcwd()\n",
    "\n",
    "os.chdir(\"C:\\\\Users\\\\DELL\\\\Desktop\")\n",
    "\n",
    "train = ImageDataGenerator(preprocessing_function=preprocess_input,\n",
    "                           shear_range=0.2,\n",
    "                           zoom_range=0.2,\n",
    "                           horizontal_flip=True,\n",
    "                           validation_split=0.4,\n",
    "                           rescale=1/255)\n",
    "\n",
    "validation = ImageDataGenerator(preprocessing_function=preprocess_input,\n",
    "                                shear_range=0.2,\n",
    "                                zoom_range=0.2,\n",
    "                                horizontal_flip=True,\n",
    "                                validation_split=0.4,\n",
    "                                rescale=1/255)\n",
    "\n",
    "train_dataset = train.flow_from_directory(traindata_dir,\n",
    "                                         target_size= (img_height, img_width),\n",
    "                                         batch_size= batch_size,\n",
    "                                         class_mode= \"categorical\",\n",
    "                                         subset='training')\n",
    "\n",
    "validation_dataset = train.flow_from_directory(validationdata_dir,\n",
    "                                         target_size= (img_height, img_width),\n",
    "                                         batch_size= batch_size,\n",
    "                                         class_mode= \"categorical\",\n",
    "                                         subset='validation')\n",
    "\n",
    "test_dataset =train.flow_from_directory(testdata_dir,\n",
    "                                         target_size= (img_height, img_width),\n",
    "                                         batch_size= 1,\n",
    "                                         class_mode= \"categorical\",\n",
    "                                         subset='validation')\n",
    "\n",
    "train_labels=train_dataset.classes\n",
    "validation_labels=test_dataset.classes\n",
    "\n",
    "x,y=test_dataset.next()\n",
    "x.shape\n",
    "\n",
    "resnet = ResNet50(\n",
    "    input_shape = (300,300,3),\n",
    "    weights = 'imagenet',\n",
    "    include_top = False  \n",
    ")\n",
    "\n",
    "resnet.summary()\n",
    "\n",
    "for layer in resnet.layers:\n",
    "    layer.trainable = False\n",
    "\n",
    "folders = glob(traindata_dir + '/*')\n",
    "folders\n",
    "\n",
    "waste_label = ['cardboard', 'glass', 'metal','paper','plastic','trash']\n",
    "\n",
    "x = Flatten() (resnet.output)\n",
    "\n",
    "prediction = Dense(len(folders), activation = 'softmax')(x)\n",
    "\n",
    "model = Model(inputs = resnet.input, outputs = prediction)\n",
    "\n",
    "model.summary()\n",
    "\n",
    "model.compile (\n",
    "    loss = 'categorical_crossentropy',\n",
    "    optimizer = 'adam',\n",
    "    metrics = ['accuracy']\n",
    ")\n",
    "\n",
    "model_fit = model.fit( train_dataset,\n",
    "                     validation_data = test_dataset,\n",
    "                     epochs = 50,\n",
    "                     steps_per_epoch = 10,\n",
    "                     validation_steps = len(test_dataset)\n",
    "                     )\n",
    "\n",
    "prediction = model.predict(test_dataset)\n",
    "prediction\n",
    "prediction = np.argmax(prediction, axis = 1)\n",
    "prediction\n",
    "\n",
    "def unseen_data_test(path, image_name, model):\n",
    "    dir_path = \"projectdataset//output dataset//test\"\n",
    "    img = image.load_img(path + image_name, target_size = IMAGE_SIZE)\n",
    "    print('Original Image')\n",
    "#     print(img)\n",
    "    plt.imshow(img)\n",
    "    x = image.img_to_array(img)\n",
    "    x = x / 255\n",
    "    x = np.expand_dims(x, axis = 0)\n",
    "    img_data = preprocess_input(x)\n",
    "    a = np.argmax(model.predict(img_data), axis = 1)\n",
    "   \n",
    "    if a == 0:\n",
    "        print(\"Its Audi\")\n",
    "    elif a == 1:\n",
    "        print(\"Its Mercedes\")\n",
    "    else:\n",
    "        print(\"Its Lamorghini \")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
